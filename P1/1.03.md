### 3. ¿Cuánto vale la entropía y la longitud de la codificación de cada símbolo para las fuentes de información de los siguientes casos? Asumir que la codificación se da bajo el código óptimo.

Notar que, en el caso equiprobable

$$H(S) = \log |S|$$

y, en general, si el código óptimo satisface $H(S) = L(C)$, entonces

$\begin{align}\nonumber
\sum_{i=1}^n p_i \log \frac{1}{p_i} = \sum_{i=1}^n p_i |C(s_i)| 
    &\iff \log \frac{1}{p_i} = |C(s_i)|\ \ \  \forall i: 1\ ...\ n\\\nonumber
    &\iff p_i := 1/2^{|C(s_i)|}
\end{align}$

Si no, podemos aproximarnos con $|C(s_i)| = \lceil  \log \frac{1}{p_i} \rceil$.

Luego,

### a) $2$ símbolos equiprobables.

$$H(S) = \log_2(2) = 1$$

Como $s_i$ tiene probabilidad $p_i = 1/2$ por ser equiprobable,

$$1/2 = 1/2^{|C(s_i)|} \implies |C(s_i)| = 1$$

$\blacksquare$

### b) $4$ símbolos equiprobables.

$$H(S) = \log_2(4) = 2$$

Como $s_i$ tiene probabilidad $p_i = 1/4$ por ser equiprobable,

$$1/4 = 1/2^{|C(s_i)|} \implies |C(s_i)| = 2$$

$\blacksquare$

### c) $6$ símbolos equiprobables.

$$H(S) = \log_2(6)$$

Como $s_i$ tiene probabilidad $p_i = 1/6$ por ser equiprobable, podemos aproximar

$$|C(s_i)| =\lceil  \log \frac{1}{p_i} \rceil = 3$$

$\blacksquare$

### d) $8$ símbolos equiprobables.

$$H(S) = \log_2(8) = 3$$

Como $s_i$ tiene probabilidad $p_i = 1/8$ por ser equiprobable,

$$1/4 = 1/2^{|C(s_i)|} \implies |C(s_i)| = 3$$

$\blacksquare$

### e) $10$ símbolos equiprobables.

$$H(S) = \log_2(10)$$

Como $s_i$ tiene probabilidad $p_i = 1/10$ por ser equiprobable, podemos aproximar

$$|C(s_i)| =\lceil  \log \frac{1}{p_i} \rceil = 4$$

$\blacksquare$

### f) $N$ símbolos equiprobables.

$$H(S) = \log n$$

y, en general, $|C(s_i)| = \lceil  \log \frac{1}{p_i} \rceil$ es el largo de la codificación de $s_i$ para el código óptimo (si $p_i = 1/2^{\alpha}$ para algún $\alpha$ natural) y, si no, para una aproximación.

$\blacksquare$
